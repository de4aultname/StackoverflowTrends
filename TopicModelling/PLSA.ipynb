{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import artm\n",
    "import copy\n",
    "import re\n",
    "\n",
    "\n",
    "def print_and_gather_measures(model, metrics):\n",
    "    print('Sparsity Phi: ', model.get_score('SparsityPhiScore').value)\n",
    "    metrics.append(model.get_score('SparsityPhiScore').value)\n",
    "\n",
    "    print('Sparsity Theta: ', model.get_score('SparsityThetaScore').value)\n",
    "    metrics.append(model.get_score('SparsityThetaScore').value)\n",
    "\n",
    "    print('Kernel contrast: ', model.get_score('TopicKernelScore').average_kernel_contrast)\n",
    "    metrics.append(model.get_score('TopicKernelScore').average_kernel_contrast)\n",
    "\n",
    "    print('Kernel purity: ', model.get_score('TopicKernelScore').average_kernel_purity)\n",
    "    metrics.append(model.get_score('TopicKernelScore').average_kernel_purity)\n",
    "\n",
    "    print('PerplexityScore: ', model.get_score('PerplexityScore').value)\n",
    "    metrics.append(model.get_score('PerplexityScore').value)\n",
    "\n",
    "    \n",
    "def get_clustering(model, topics):\n",
    "    phi_matrix = copy.deepcopy(model.phi_)\n",
    "    pattern = '\\(\\'@default_class\\', \\'(.*?)\\'\\)'\n",
    "    cleaned_index = [re.search(pattern, str(x)).group(1) for x in phi_matrix.index.tolist()]\n",
    "    phi_matrix.index = cleaned_index\n",
    "    num_topics = len(topics)\n",
    "    clustering = [list() for _ in range(num_topics)]\n",
    "    for i in range(num_topics):\n",
    "        current_topic = topics[i]\n",
    "        phi_matrix.sort_values(by = current_topic, ascending = False, inplace = True)\n",
    "        top_tokens = phi_matrix.index[phi_matrix[current_topic] > 0]\n",
    "        clustering[i] = top_tokens\n",
    "    return clustering\n",
    "\n",
    "def print_clustering(clustering, topics):\n",
    "    num_topics = len(topics)\n",
    "    for i in range(num_topics):\n",
    "        print(topics[i])\n",
    "        print(clustering[i])\n",
    "        print(len(clustering[i]))\n",
    "        \n",
    "def save_clustering(clustering, topics, filename):\n",
    "    f = open(filename, \"w\")\n",
    "    num_topics = len(topics)\n",
    "    for i in range(num_topics):\n",
    "        f.write(topics[i])\n",
    "        f.write(\"\\n Amount of tags in cluster: \")\n",
    "        f.write(str(len(clustering[i])))\n",
    "        f.write(\"\\n\")\n",
    "        for j in range(len(clustering[i])):\n",
    "            f.write(clustering[i][j])\n",
    "            f.write(\", \")\n",
    "        f.write(\"\\n\")\n",
    "    f.close()\n",
    "    \n",
    "def print_top_tags(score_tracker):\n",
    "    topics = score_tracker.topic_name\n",
    "    tags = score_tracker.token\n",
    "    weights = score_tracker.weight\n",
    "    for i in range(1, len(topics) + 1):\n",
    "        if ((topics[i-1] != topics[i]) | (i == 1)):\n",
    "            print(topics[i])\n",
    "        print('{}: {}, '.format(tags[i], weights[i]))\n",
    "        \n",
    "def save_top_tags(score_tracker, filename):\n",
    "    f = open(filename, \"w\")\n",
    "    topics = score_tracker.topic_name\n",
    "    tags = score_tracker.token\n",
    "    weights = score_tracker.weight\n",
    "    for i in range(1, len(topics)):\n",
    "        if ((topics[i-1] != topics[i]) | (i == 1)):\n",
    "            f.write(topics[i])\n",
    "            f.write(\"\\n\")\n",
    "        f.write('{}: {}; \\n '.format(tags[i], weights[i]))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 04 (ARTM, num_topics = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Batch', max=18125, style=ProgressStyle(description_width='iniâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "#batch_vectorizer = artm.BatchVectorizer(data_path='vw.tags.100.txt', data_format='vowpal_wabbit',target_folder='posts-tags-100')\n",
    "#dictionary = batch_vectorizer.dictionary\n",
    "\n",
    "topic_names = ['topic_{}'.format(i) for i in range(1000)]\n",
    "model_artm = artm.ARTM(topic_names = topic_names, num_processors = 4,\n",
    "                       scores = [artm.PerplexityScore(name = 'PerplexityScore', dictionary = dictionary), \n",
    "                                artm.SparsityPhiScore(name = 'SparsityPhiScore'),\n",
    "                                artm.SparsityThetaScore(name = 'SparsityThetaScore'), \n",
    "                                artm.TopicKernelScore(name = 'TopicKernelScore', probability_mass_threshold = 0.1),\n",
    "                                artm.TopTokensScore(name = 'TopTokensScore', num_tokens = 20)],\n",
    "                       seed = 62, show_progress_bars = True)\n",
    "\n",
    "\n",
    "model_artm.initialize(dictionary=dictionary)\n",
    "model_artm.regularizers.add(artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau = -0.5))\n",
    "\n",
    "model_artm.fit_online(batch_vectorizer = batch_vectorizer, asynchronous = True)\n",
    "model_artm.dump_artm_model(\"model_artm_04\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity Phi:  1.0\n",
      "Sparsity Theta:  0.999890148639679\n",
      "Kernel contrast:  0.0\n",
      "Kernel purity:  0.0\n",
      "PerplexityScore:  946.3243408203125\n"
     ]
    }
   ],
   "source": [
    "metrics_04 = []\n",
    "print_and_gather_measures(model_artm, metrics_04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = get_clustering(model_artm, topic_names)\n",
    "#print_clustering(clustering, topic_names)\n",
    "save_clustering(clustering, topic_names, \"clustering_04.txt\")\n",
    "#print_top_tags(model_plsa.get_score('TopTokensScore'))\n",
    "save_top_tags(model_artm.get_score('TopTokensScore'), \"top_tags_04.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 02 (+ Decorrelation Regularizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artm = copy.deepcopy(model_plsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecorrelatorPhiRegularizer is too slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_plsa.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_regularizer'))\n",
    "model_plsa.regularizers['decorrelator_phi_regularizer'].tau = 100\n",
    "model_plsa.fit_online(batch_vectorizer = batch_vectorizer, asynchronous = True)\n",
    "model_plsa.dump_artm_model(\"model_artm_02_decorrelator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying another regularizer with similar effect --- SmoothSparsePhiRegularizer (we want to make $\\Phi$ more sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artm.regularizers.add(artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau = -0.5))\n",
    "model_artm.fit_online(batch_vectorizer = batch_vectorizer, asynchronous = True)\n",
    "model_artm.dump_artm_model(\"model_artm_03_sparse_phi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity Phi:  0.9999796748161316\n",
      "Sparsity Theta:  0.9983083009719849\n",
      "Kernel contrast:  0.26499998569488525\n",
      "Kernel purity:  0.26499998569488525\n",
      "PerplexityScore:  76.6322250366211\n"
     ]
    }
   ],
   "source": [
    "metrics_02 = []\n",
    "print_and_gather_measures(model_artm, metrics_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = get_clustering(model_artm, topic_names)\n",
    "#print_clustering(clustering, topic_names)\n",
    "save_clustering(clustering, topic_names, \"clustering_02.txt\")\n",
    "#print_top_tags(model_artm.get_score('TopTokensScore'))\n",
    "save_top_tags(model_artm.get_score('TopTokensScore'), \"top_tags_02.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
